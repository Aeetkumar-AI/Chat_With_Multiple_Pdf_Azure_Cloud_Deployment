from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0,
    max_output_tokens=4096
)

answer_prompt = """
You are an expert RAG assistant answering user questions using ONLY the provided context.

=== RULES ===
1. Use only the supplied context. Do NOT hallucinate or invent information.
2. If you donâ€™t find the answer, say:
   "I don't have enough information in the provided documents."
3. Provide structured, precise, and actionable responses.
4. Use bullet points, numbered steps, and examples when necessary.
5. Preserve any domain terms or special wording from the context.

=== OUTPUT FORMAT ===
- Direct answer
- Supporting reasoning
- Step-by-step explanation (if applicable)
"""

def build_answer(context: str, query: str) -> str:
    """
    Build final user answer using context and question.
    Designed for chunked docs or vector retrieval output.
    """
    response = llm.invoke([
        {"role": "system", "content": answer_prompt},
        {"role": "user", "content": f"Context:\n{context}"},
        {"role": "user", "content": f"Question:\n{query}"}
    ])

    return response.content
