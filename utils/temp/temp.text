def determine_severity_with_domain_mapping(summary, description, acceptance_criteria, domain):
    """
    Returns severity assessment as tuple with enhanced error handling and validation
    Returns: (change_type, severity_score, severity_label, recommendation, subcategory, risk_factors, reasoning)
    """
    # Input validation
    if not summary and not description:
        return ("Unknown", 5, "Medium", "Needs Review", "Insufficient Information", ["No summary or description provided"], "Cannot assess without story details")
    
    # Create fallback values
    fallback_values = ("Major", 5, "Medium", "Needs Review", "Unable to determine", ["Assessment error"], "Error during assessment - using conservative values")
    
    try:
        prompt = create_domain_specific_prompt(summary, description, acceptance_criteria, domain)
        
        # Add retry logic for API calls
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = generate_content(prompt)
                
                # Check if response is empty or None
                if not response or not hasattr(response, 'text') or not response.text.strip():
                    if attempt < max_retries - 1:
                        print(f"Empty response, retry {attempt + 1}/{max_retries}")
                        time.sleep(1)  # Wait before retry
                        continue
                    else:
                        print("All retries failed - empty response")
                        return fallback_values
                
                # Try to parse JSON
                try:
                    result = json.loads(response.text.strip())
                except json.JSONDecodeError as json_error:
                    print(f"JSON decode error: {json_error}")
                    print(f"Raw response: {response.text[:200]}...")
                    if attempt < max_retries - 1:
                        continue
                    else:
                        return fallback_values
                
                # Validate required fields exist
                required_fields = ["change_type", "severity_score", "severity_label", "recommendation"]
                if not all(field in result for field in required_fields):
                    print(f"Missing required fields. Available: {list(result.keys())}")
                    if attempt < max_retries - 1:
                        continue
                    else:
                        return fallback_values
                
                # Validate values are not just field names
                change_type = result.get("change_type", "Major")
                if change_type.lower() in ["change_type", "changetype", "type"]:
                    change_type = "Major"  # Default if LLM returned field name
                
                severity_label = result.get("severity_label", "Medium")
                if severity_label.lower() in ["severity_label", "severitylabel", "label"]:
                    severity_label = "Medium"
                
                recommendation = result.get("recommendation", "Needs Review")
                if recommendation.lower() in ["recommendation", "recommend"]:
                    recommendation = "Needs Review"
                
                # Validate and convert severity score
                try:
                    severity_score = int(result.get("severity_score", 5))
                    if not 1 <= severity_score <= 10:
                        severity_score = 5
                except (ValueError, TypeError):
                    severity_score = 5
                
                # Extract other fields with defaults
                subcategory = result.get("subcategory_identified", "General assessment")
                if subcategory.lower() in ["subcategory", "subcategory_identified"]:
                    subcategory = "General assessment"
                
                risk_factors = result.get("risk_factors_identified", [])
                if isinstance(risk_factors, str):
                    risk_factors = [risk_factors]
                elif not isinstance(risk_factors, list):
                    risk_factors = ["Risk assessment completed"]
                
                reasoning = result.get("reasoning", "Assessment based on domain analysis")
                if reasoning.lower() in ["reasoning", "reason"]:
                    reasoning = "Assessment based on domain analysis"
                
                # Return successful assessment
                return (
                    change_type,
                    severity_score,
                    severity_label,
                    recommendation,
                    subcategory,
                    risk_factors,
                    reasoning
                )
                
            except Exception as api_error:
                print(f"API call error (attempt {attempt + 1}): {api_error}")
                if attempt < max_retries - 1:
                    time.sleep(2)  # Wait longer before retry
                    continue
                else:
                    print("All API retries failed")
                    return fallback_values
        
        # If we get here, all retries failed
        return fallback_values
        
    except Exception as e:
        print(f"Unexpected error in severity assessment: {e}")
        return fallback_values

def convert_list_to_excel(stories):
    """
    Convert a list of processed stories to an Excel file with proper error handling.
    """
    try:
        # Create DataFrame with all expected columns
        df = pd.DataFrame(stories, columns=[
            "issue_key",
            "summary",
            "description", 
            "acceptance_criteria",
            "Flag",
            "Reason",
            "IS Impact",
            "Security Domain",
            "Domain Justification",
            "Change_Type",
            "Severity_Score", 
            "Severity_Label",
            "Recommendation",
            "Subcategory", 
            "Risk_Factors",
            "Reasoning"
        ])
        
        # Clean up any remaining field name artifacts
        cleanup_mappings = {
            "change_type": "Major",
            "severity_score": "5", 
            "severity_label": "Medium",
            "recommendation": "Needs Review",
            "subcategory": "General",
            "risk_factors": "Assessment completed",
            "reasoning": "Standard assessment"
        }
        
        for col in ["Change_Type", "Severity_Label", "Recommendation", "Subcategory", "Risk_Factors", "Reasoning"]:
            if col in df.columns:
                df[col] = df[col].replace(cleanup_mappings)
        
        # Convert Risk_Factors list to string if needed
        if "Risk_Factors" in df.columns:
            df["Risk_Factors"] = df["Risk_Factors"].apply(
                lambda x: "; ".join(x) if isinstance(x, list) else str(x)
            )
        
        # Create Excel file
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            df.to_excel(writer, index=False, sheet_name="Processed Stories")
        
        output.seek(0)
        return output.getvalue()
        
    except Exception as e:
        st.error(f"Error converting to Excel: {e}")
        return None

def determine_severity_with_domain_mapping(summary, description, acceptance_criteria, domain):
    """
    Returns severity assessment as tuple to match your existing code structure
    Returns: (change_type, severity_score, severity_label, recommendation, subcategory, risk_factors, reasoning)
    """
    prompt = create_domain_specific_prompt(summary, description, acceptance_criteria, domain)
    
    try:
        response = generate_content(prompt)
        result = json.loads(response.text)
        
        # Enhanced validation
        required_fields = ["change_type", "severity_score", "severity_label", "recommendation", "subcategory_identified"]
        if not all(field in result for field in required_fields):
            raise ValueError("Missing required fields in LLM response")
            
        severity_score = int(result.get("severity_score", 5))
        if not 1 <= severity_score <= 10:
            severity_score = 5  # Default to medium if out of range
            
        # Return as tuple to match your existing code
        return (
            result.get("change_type", "Unknown"),
            severity_score,
            result.get("severity_label", "Medium"),
            result.get("recommendation", "Needs Review"),
            result.get("subcategory_identified", "Unknown"),
            result.get("risk_factors_identified", []),
            result.get("reasoning", "Assessment based on domain analysis")
        )
        
    except Exception as e:
        print(f"Error in severity assessment: {e}")
        # Conservative fallback - return tuple
        return (
            "Unknown",
            5,
            "Medium", 
            "Needs Review",
            "Unable to determine",
            ["Assessment error"],
            "Error occurred during assessment, defaulting to conservative evaluation"
        )

def process_stories(df, progress_bar):
    """
    Process the Jira stories and evaluate their quality.
    """
    try:
        stories = []
        total_rows = len(df)
        
        for index, row in df.iterrows():
            story = {
                "issue_key": row.get("Key", ""),
                "summary": row.get("Summary", ""),
                "description": row.get("Description", ""),
                "acceptance_criteria": row.get("Acceptance Criteria", ""),
            }
            
            # Evaluate story quality
            decision, reasons = evaluate_story_quality(
                story["summary"], 
                story["description"], 
                story["acceptance_criteria"]
            )
            story["Flag"] = decision
            story["Reason"] = "\n".join(reasons)
            
            # Only process IS impact if story quality is good
            if decision.lower() == "good":
                is_impact, domain, justification = determine_is_impact_and_domain(
                    story["summary"], 
                    story["description"], 
                    story["acceptance_criteria"]
                )
                
                story["IS Impact"] = is_impact
                story["Security Domain"] = domain
                story["Domain Justification"] = justification
                
                # Only do severity assessment if there is IS impact
                if is_impact.lower() == "yes":
                    try:
                        change_type, severity_score, severity_label, recommendation, subcategory, risk_factors, reasoning = determine_severity_with_domain_mapping(
                            story["summary"], 
                            story["description"], 
                            story["acceptance_criteria"], 
                            domain
                        )
                        
                        story["Change_Type"] = change_type
                        story["Severity_Score"] = severity_score
                        story["Severity_Label"] = severity_label
                        story["Recommendation"] = recommendation
                        story["Subcategory"] = subcategory
                        story["Risk_Factors"] = risk_factors if isinstance(risk_factors, str) else "; ".join(risk_factors)
                        story["Reasoning"] = reasoning
                        
                    except Exception as severity_error:
                        print(f"Error in severity assessment for story {story['issue_key']}: {severity_error}")
                        # Set default values for severity assessment
                        story["Change_Type"] = "Unknown"
                        story["Severity_Score"] = 5
                        story["Severity_Label"] = "Medium"
                        story["Recommendation"] = "Needs Review"
                        story["Subcategory"] = "Error in assessment"
                        story["Risk_Factors"] = "Assessment failed"
                        story["Reasoning"] = f"Error during assessment: {str(severity_error)}"
                else:
                    # No IS impact - set empty severity fields
                    story["Change_Type"] = "N/A"
                    story["Severity_Score"] = 0
                    story["Severity_Label"] = "N/A"
                    story["Recommendation"] = "No IS Impact"
                    story["Subcategory"] = "N/A"
                    story["Risk_Factors"] = "N/A"
                    story["Reasoning"] = "No information security impact identified"
            else:
                # Poor quality story - set all fields to indicate quality issues
                story["IS Impact"] = "N/A"
                story["Security Domain"] = "N/A"
                story["Domain Justification"] = "Story quality insufficient for assessment"
                story["Change_Type"] = "N/A"
                story["Severity_Score"] = 0
                story["Severity_Label"] = "N/A"
                story["Recommendation"] = "Improve Story Quality"
                story["Subcategory"] = "N/A"
                story["Risk_Factors"] = "N/A"
                story["Reasoning"] = "Story quality must be improved before assessment"
            
            stories.append(story)
            
            # Update progress
            progress = (index + 1) / total_rows
            progress_bar.progress(
                progress, 
                text=f"Analyzing story {index + 1} of {total_rows}: {story['issue_key']}"
            )
            time.sleep(0.1)  # Small delay to make progress visible
            
        return stories
        
    except Exception as e:
        st.error(f"Error processing stories: {e}")
        return []

# Also provide your original determine_severity function updated to use the new logic
def determine_severity(summary, description, acceptance_criteria, domain):
    """
    Original function signature maintained for backward compatibility
    Returns: (change_type, severity_score, severity_label, recommendation)
    """
    try:
        change_type, severity_score, severity_label, recommendation, subcategory, risk_factors, reasoning = determine_severity_with_domain_mapping(
            summary, description, acceptance_criteria, domain
        )
        return change_type, severity_score, severity_label, recommendation
    except Exception as e:
        print(f"Error in determine_severity: {e}")
        return "Unknown", 5, "Medium", "Needs Review"
